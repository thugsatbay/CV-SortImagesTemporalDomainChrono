{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/gdhody/.conda/envs/py_tensor/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import scipy.io as sio \n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import time\n",
    "import pickle\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.data_utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChronoDataSet(Sequence):\n",
    "    def __init__(self,\n",
    "                label_file_path,\n",
    "                data_file_path,\n",
    "                batch_size=128,\n",
    "                start_epoch=0,\n",
    "                mode='TRAIN',\n",
    "                dataset='UCF'):\n",
    "\n",
    "        '''\n",
    "        Constant parameters\n",
    "        '''\n",
    "        self.n_frames = 4\n",
    "        self.image_padding = 20\n",
    "        self.image_size = 80\n",
    "        self.image_jitter = 5\n",
    "        self.channels = 3\n",
    "        self.epoch = start_epoch + 1\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.order_type = [\n",
    "                            list(ele) for ele in \n",
    "                            itertools.permutations(range(self.n_frames)) \n",
    "                            if list(ele) != [0,1,2,3] and list(ele) != [3,2,1,0]\n",
    "                          ]\n",
    "\n",
    "#         TRAIN_UCF, TRAIN_HMDB = [], []\n",
    "#         with open(label_file_path, 'rb') as f:\n",
    "#             TRAIN_UCF, TRAIN_HMDB = pickle.load(f)\n",
    "        \n",
    "#         self.label = TRAIN_UCF\n",
    "#         if dataset == 'HMDB':\n",
    "#             self.label = TRAIN_HMDB\n",
    "            \n",
    "        self.data_file_path = data_file_path\n",
    "        \n",
    "        data = h5py.File(data_file_path,'r')\n",
    "        \n",
    "        self.samples = data['train_img'].shape[0]\n",
    "        \n",
    "        self.mode = \"train_img\"\n",
    "        if mode == \"VALIDATION\":\n",
    "            self.mode = \"val_img\"\n",
    "            self.samples = data['val_img'].shape[0]\n",
    "        elif mode == \"TEST\":\n",
    "            print \"TEST MODE INITIALIZED\"\n",
    "            self.mode = \"test_img\"\n",
    "            self.samples = data['test_img'].shape[0]\n",
    "            \n",
    "        data.close()\n",
    "        \n",
    "        self.blocks = [item for item in xrange(0, self.samples, self.batch_size)][:-1]\n",
    "        self.current_img_size = self.image_size + self.image_padding\n",
    "\n",
    "    def getBlocks(self):\n",
    "        return self.blocks;\n",
    "    \n",
    "    def __len__(self):\n",
    "        # return batch size?\n",
    "        return int(self.samples / self.batch_size)\n",
    "\n",
    "    def getBatchRunsPerEpoch(self):\n",
    "        return int(self.samples / self.batch_size)\n",
    "\n",
    "    def opticalFlow(frame1, frame2):\n",
    "        hsv = np.zeros_like(frame1)\n",
    "        hsv[...,1] = 255\n",
    "        flow = cv2.calcOpticalFlowFarneback(cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY), cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY), None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        hsv[...,0] = ang*180/np.pi/2\n",
    "        hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "        return cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    def jitter_image(self, image):\n",
    "        startxy = (np.random.randint(0, self.image_padding), np.random.randint(0, self.image_padding))\n",
    "        \n",
    "        # Start points by default\n",
    "        newx, newy = startxy[0], startxy[1]\n",
    "        \n",
    "        # Jitter points\n",
    "        sx, sy = random.randint(-self.image_jitter, self.image_jitter), random.randint(-self.image_jitter, self.image_jitter)\n",
    "        \n",
    "        # Jitter should not move the crop window outside the image\n",
    "        if startxy[0] + sx > 0 and startxy[0] + self.image_size + sx < self.current_img_size: newx += sx \n",
    "        if startxy[1] + sy > 0 and startxy[1] + self.image_size + sy < self.current_img_size: newy += sy\n",
    "        return image[newx : newx + self.image_size, newy : newy + self.image_size, ...]\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        random.shuffle(self.blocks)\n",
    "        print \"\\nEPOCH\", self.epoch, \"Ends. Data blocks shuffled!\"\n",
    "        self.epoch += 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        start_time = time.time()\n",
    "            \n",
    "        idxcounter = idx % self.getBatchRunsPerEpoch()\n",
    "        \n",
    "        with h5py.File(self.data_file_path,'r') as f:\n",
    "            batch_data = f[self.mode][self.blocks[idxcounter]:self.blocks[idxcounter] + self.batch_size, ...]\n",
    "        np.random.shuffle(batch_data)\n",
    "        \n",
    "        # Spatial Jittering\n",
    "        images = [[self.jitter_image(each_image) for each_image in sample] \n",
    "                  for sample in batch_data]\n",
    "        \n",
    "\n",
    "        # Horizontal Flip\n",
    "        images = [[cv2.flip(images[index][image_index], 1) for image_index in xrange(self.n_frames)] \n",
    "                  if np.random.randint(0,2) else images[index] for index in xrange(self.batch_size)]\n",
    "        \n",
    "\n",
    "        # Channel Splitting\n",
    "        images = [[np.stack((images[index][image_index][:,:,np.random.randint(0, 3)],)*3, axis=2) \n",
    "                   for image_index in xrange(self.n_frames)] for index in xrange(self.batch_size)]\n",
    "        \n",
    "#         for image in images:\n",
    "#             print len(image), image[0].shape, image[1].shape, image[2].shape, image[3].shape\n",
    "        \n",
    "        # Randomly +ve and -ve test case\n",
    "        images = [(np.stack(tuple([images[index][random_index] \n",
    "                  for random_index in self.order_type[np.random.randint(0, len(self.order_type))]]), axis=0), 0) \n",
    "                  if np.random.randint(0,2) else (images[index][::1 * ((-1)**(np.random.randint(0,2) + 1))], 1) for index in xrange(self.batch_size)]\n",
    "        \n",
    "#         print \"After labelling\"\n",
    "#         for image in images:\n",
    "#             print len(image[1]), image[1][0].shape, image[1][1].shape, image[1][2].shape, image[1][3].shape\n",
    "\n",
    "        labels = np.array([label for _, label in images])\n",
    "\n",
    "        images = np.array([image for image, _ in images])\n",
    "        \n",
    "        images = np.array(images, dtype=np.float32)\n",
    "        \n",
    "        images -= 97.3\n",
    "        \n",
    "#         if not (idxcounter + 1)%500:\n",
    "#             print \"\\nLOAD TIME | Epoch\", str(self.epoch), \"| Batch\", str(self.blocks[idxcounter]), \"| processed with time : \", str(time.time() - start_time), \"\\n\"\n",
    "        \n",
    "        return (images, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Testing of the module*\n",
    "```\n",
    "TYNAMO_HOME_DIR = '/nfs/tynamo/home/data/vision7/gdhody/chrono/'\n",
    "BLITZLE_HOME_DIR = '/nfs/blitzle/home/data/vision5/gdhody/chrono/'\n",
    "HOME_DIR = TYNAMO_HOME_DIR\n",
    "HDF5_PATH = os.path.join(HOME_DIR, 'patch.hdf5')\n",
    "PICKLE_PATH = os.path.join(HOME_DIR, 'patch.pkl')\n",
    "cds = ChronoDataSet(PICKLE_PATH, HDF5_PATH)\n",
    "cds.__getitem__(99)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 80, 80, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "157.7"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# TYNAMO_HOME_DIR = '/nfs/tynamo/home/data/vision7/gdhody/chrono/'\n",
    "# BLITZLE_HOME_DIR = '/nfs/blitzle/home/data/vision5/gdhody/chrono/'\n",
    "# HOME_DIR = TYNAMO_HOME_DIR\n",
    "# HDF5_PATH = os.path.join(HOME_DIR, 'patch.hdf5')\n",
    "# PICKLE_PATH = os.path.join(HOME_DIR, 'patch.pkl')\n",
    "# cds = ChronoDataSet(PICKLE_PATH, HDF5_PATH)\n",
    "# print cds.__getitem__(50)[0][0].shape\n",
    "# np.amax(cds.__getitem__(50)[0][0])\n",
    "# for inn, frames in enumerate(im):\n",
    "#     index = 1\n",
    "#     print inn, frames.shape\n",
    "#     plt.figure()\n",
    "#     plt.subplots_adjust(wspace=1, hspace=1)\n",
    "#     plt.subplots(figsize=(15, 20))\n",
    "#     for frame in frames:\n",
    "#         suub_plt = plt.subplot(1, 4, index)\n",
    "#         plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), interpolation='nearest', aspect='equal')\n",
    "#         index += 1\n",
    "# print l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.27416\n"
     ]
    }
   ],
   "source": [
    "# TYNAMO_HOME_DIR = '/nfs/tynamo/home/data/vision7/gdhody/chrono/'\n",
    "# BLITZLE_HOME_DIR = '/nfs/blitzle/home/data/vision5/gdhody/chrono/'\n",
    "# HOME_DIR = TYNAMO_HOME_DIR\n",
    "# HDF5_PATH = os.path.join(HOME_DIR, 'patch.hdf5')\n",
    "# with h5py.File(HDF5_PATH,'r') as f:\n",
    "#     print np.mean(f['train_img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# TYNAMO_HOME_DIR = '/nfs/tynamo/home/data/vision7/gdhody/chrono/'\n",
    "# BLITZLE_HOME_DIR = '/nfs/blitzle/home/data/vision5/gdhody/chrono/'\n",
    "# HOME_DIR = TYNAMO_HOME_DIR\n",
    "# HDF5_PATH = os.path.join(HOME_DIR, 'patch.hdf5')\n",
    "# PICKLE_PATH = os.path.join(HOME_DIR, 'patch.pkl')\n",
    "# cds = ChronoDataSet(PICKLE_PATH, HDF5_PATH)\n",
    "# cds.__getitem__(50)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
